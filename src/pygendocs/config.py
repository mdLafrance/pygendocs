"""Functionality to parse user defined config variables.
"""

from enum import Enum
from typing import Optional

import tomli

from pydantic import BaseModel


class LLMConfiguration(BaseModel):
    model: str
    max_tokens: int = 800
    base_url: Optional[str] = None


class DocstringStyle(str, Enum):
    reST = "reST"
    Google = "Google"
    Epytext = "Epytext"
    Numpydoc = "Numpydoc"


class PyGenDocsConfiguration(BaseModel):
    """
    Data struct encoding configuration options for PyGenDocs.

    This class should be considered the 'source of truth' with regards to supported
    syntax and options in pyproject.toml.
    """

    ignore_internal: bool = False
    """Whether or not to ignore objects and functions beginning with an underscore."""

    ignore_private: bool = True
    """Whether or not to ignore objects and functions beginning with a double underscore."""

    ignore_constructors: bool = False
    """Whether or not to ignore class constructor __init__ functions. Defaults to True."""

    coverage_threshold: float = 100

    include_fixme_header: bool = True
    """Whether or not to prepend an additional line of documentation containing a FIXME: 
    tag signalling that this docstring was autogenerated and should be reviewed."""

    docstring_style: DocstringStyle = DocstringStyle.Google
    """The style with which the generated docstring should be written. 
    
    Defaults to Google python style.
    """

    llm_api_url: str = None  # "https://api.openai.com/v1/chat/completions"
    """The environment variable from which the url of the chosen llm api is hosted.
    
    Defaults to openai chatgpt completion endpoint.
    """

    llm_api_token_env_key: str = "OPENAI_API_KEY"
    """The environment variable from which any required llm api token will be read from.

    Defaults to the standard openai api key.
    """

    llm_model: str = "gpt-4"
    """String name of the model which should be used for completions."""

    llm_completion_max_tokens: int = 800
    """Token limit for responses. See openai api documentation for more information
    about tokens """

    class config:
        """Needed for pydantic to support arbitrary types."""

        allow_arbitrary_types = True

    @property
    def llm_configuration(self) -> LLMConfiguration:
        return LLMConfiguration(
            model=self.llm_model,
            max_tokens=self.llm_completion_max_tokens,
            base_url=self.llm_api_url,
        )


def read_from_toml(config_file: str = "pyproject.toml") -> PyGenDocsConfiguration:
    """Load the configuration for the given project from the project's toml file."""
    try:
        with open(config_file, "r") as f:
            config_dict = tomli.loads(f.read()).get("tool", {}).get("pygendocs", {})
    except FileNotFoundError:
        config_dict = {}

    return PyGenDocsConfiguration(**config_dict)
